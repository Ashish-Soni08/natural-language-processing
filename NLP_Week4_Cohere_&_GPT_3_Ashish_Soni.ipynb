{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 4: Cohere + GPT-3\n",
        "\n",
        "### What are we building\n",
        "We came a long way these past couple a weeks. We learned how to work with Word Vectors, RNNs and Transformers. Each consequtive week the model improved by ✨a lot✨\n",
        "\n",
        "Now, for our last project we want to encourage you try and implement some ideas you might have had when you joined this course, using one the latest Transformer: GPT-3 or a similar (small) model through Co:here!\n",
        "\n",
        "### Instructions\n",
        "We will provide you some quick pointers to get you started with GPT-3 and also provide ideas that you might try to implement if you are not sure yet what you would like to try.\n",
        "\n",
        "Some suggestions:\n",
        "- https://docs.cohere.ai/prompt-engineering-wiki/\n",
        "- https://docs.cohere.ai/react-generate-example/\n",
        "- https://github.com/elyase/awesome-gpt3\n",
        "- https://www.educative.io/blog/top-uses-gpt-3-deep-learning\n",
        "- https://gpt3demo.com/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SFgTZBUYWUyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "\n",
        "✨ Now let's get started! To kick things off, as always, we will install some dependencies."
      ],
      "metadata": {
        "id": "59OmLGSGiUIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.15.0"
      ],
      "metadata": {
        "id": "M7XKspxliQyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61b8548-ecb9-44de-c6f7-e0dd1efbde4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai==0.15.0\n",
            "  Downloading openai-0.15.0.tar.gz (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai==0.15.0) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai==0.15.0) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.9/dist-packages (from openai==0.15.0) (1.3.5)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.3.230304-py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.9/dist-packages (from openai==0.15.0) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl>=3.0.7->openai==0.15.0) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.3->openai==0.15.0) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.3->openai==0.15.0) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.2.3->openai==0.15.0) (1.22.4)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.1.2-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.15.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.15.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.15.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai==0.15.0) (1.26.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai==0.15.0) (1.15.0)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.15.0-py3-none-any.whl size=50093 sha256=32cc45e56874bb240b0ad1425bbb58048d61711143c91db258d9a881bc64966e\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/c9/5f/4657e7962ae17dd5b5896d08d7eaaf4b13c704419fb273ba0e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.15.0 pandas-stubs-1.5.3.230304 types-pytz-2022.7.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Key\n",
        "We need an API key from OpenAI:\n",
        "- Create an [account](https://beta.openai.com/signup)\n",
        "- Go to this [link](https://beta.openai.com/account/api-keys) to create an API key\n",
        "- Use the secret key as API key\n"
      ],
      "metadata": {
        "id": "e_IpF-woiX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "yIty-nbeiYeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial\n",
        "\n",
        "Below an example of how you could query GPT-3!\n",
        "\n",
        "The [GitHub repo](https://github.com/openai/openai-python) contains more examples, while the [API](https://beta.openai.com/docs/api-reference?lang=python) provides more insight into the available options."
      ],
      "metadata": {
        "id": "5DUMuvlXjp2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please feel free to modify the HParams. More information about the available options can be found [here](https://beta.openai.com/docs/api-reference/completions/create).\n",
        "\n"
      ],
      "metadata": {
        "id": "IHQ5_KE4oCIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HParams:\n",
        "  engine: str = \"ada\"\n",
        "  temperature: float = 0.7\n",
        "  max_tokens: int = 1000\n",
        "  top_p: float = 1.0\n",
        "  frequency_penalty: float = 0.52\n",
        "  presence_penalty: float = 0.5\n",
        "  stop: str = \"11.\"\n",
        "\n",
        "\n",
        "class GPT3TextResponse():\n",
        "  def response(self, prompt):\n",
        "    response = openai.Completion.create(\n",
        "      engine=HParams.engine,\n",
        "      prompt=prompt,\n",
        "      temperature=HParams.temperature,\n",
        "      max_tokens=HParams.max_tokens,\n",
        "      top_p=HParams.top_p,\n",
        "      frequency_penalty=HParams.frequency_penalty,\n",
        "      presence_penalty=HParams.presence_penalty,\n",
        "      stop=[HParams.stop]\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "\n",
        "question = \"GPT-3 ideas\\n\\n\\n1. Classifying Reddit posts\\n2. Generating Twitter tweets\\n3.\"\n",
        "\n",
        "gpt3 = GPT3TextResponse().response(question)\n",
        "print(gpt3)"
      ],
      "metadata": {
        "id": "u9gxN6r9jlmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea7c57b-705c-4c1e-883a-7a7dfa160642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Creating a comment thread\n",
            "4. Redirecting the user to another page\n",
            "\n",
            "\n",
            "In this section, you will learn how to:\n",
            "\n",
            "Create a URL for Twitter posts.\n",
            "\n",
            "\n",
            "Generate a Twitter tweet from Reddit in less than 5 seconds.\n",
            "\n",
            "\n",
            "Create a comment that includes an image of your favorite Pokemon.\n",
            "\n",
            "\n",
            "Pipe-up your comments to other websites so people can read them and comment on them, too.\n",
            "\n",
            "\n",
            "This section is based on my personal experience with Reddit and my own writing and teaching methodology as applied to online communities (see \"Reddit Lessons Learned\"). The information presented here is based on the most successful implementation I have seen of interactions between third-party content providers and their audience by employing off-the-shelf tools like GojiMail/MailChimp, which are designed to work with many different email services. This approach allows users to be more useful rather than provide an individual service with an agenda clearly defined by the provider (readers), while still allowing users access to the content they want without sacrificing privacy or security.  I will also use these same tools in later sections of this book, because they are at least as effective in creating conversations that link together interests across networks (such as email) as they are within one network (Twitter). For more information about using off-the-shelf tools for creating digital content, see \"Learn How To Use Email Tools For Creating Content\".  The following sections will explain how you can use some of them to create your own version of what you do today; others may be used by third parties who want to integrate their own offerings into your existing online community structure.  As you create new content, take note that it only takes a small amount of effort per day over time to make all of these changes unnoticed by others who might otherwise visit your site asking questions or providing feedback. If there's something else you'd like me to discuss further regarding off-the-shelf tools for creating data driven content—or if I've missed something important about off-the-shelf products for creating digital media—please let me know! As long as you're willing, sharing this information is encouraged!  I'm looking forward to hearing from all of you! You can follow me at @jt_skyler or follow @JTSkyler on Twitter . Please check out my blog: http://www1blogger/blogger?blogId=jt_skyler . If you're interested in learning about how we created the social graph for our website, click here: http://contentforinterestingdemos.com/socialgraph/?posto=133436#postid=133436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\" This is a conversation between a student and a polite, helpful Natural Language Processing (NLP) Course Instructor.\n",
        "               Question of the student: Hi, I'd like to know about the next steps after finsihing the course.  How can I get job in the field? What should I do next to become better in NLP?\n",
        "               Response by the Natural Language Processing Course (NLP) Instructor: very good questions, you should do more projects and start making a portfolio to show your skills to instructors which will be helpful in both scenarios,\n",
        "               \"\"\"\n",
        "\n",
        "gpt3 = GPT3TextResponse().response(question)\n",
        "print(gpt3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyOkFWofy_qr",
        "outputId": "2abb61ba-1ede-4f79-d4d8-6f7387684334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \n",
            "\n",
            "Programming Language and NLP can be very helpful for different projects. The key ideas are:\n",
            "1) Describe the problem, the tasks, the processes and the goals to improve or develop a problem-solving language. In our example we will see how to describe a problem in NLP and make it more understandable by some help of an easy to understand programming language (Python).\n",
            "\n",
            "2) Choose an easy to learn programming language that contains a lot of useful features. A good example is Java which is an open source platform as well as a programming language. We can also choose another one like Python or Racket which has some interesting features. I will explain on this next topic in the following section.\n",
            "\n",
            "3) Fill out the solution with true errors and false errors, usually errors will come when we have ignored important data or when we use incorrect steps or missing information. This approach is helpful because we can distinguish between true errors and false errors without having to do complicated task of coding error messages for every step/step combination in our program (We will introduce this concept later).\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✨ Your idea ✨\n",
        "\n",
        "We really want to encourage to try one of your own ideas or take an idea from the previously suggested links and see if you can come up with something (or maybe let GPT-3 help you come up with an idea?).\n",
        "\n",
        "As always, if you have any questions or like to brainstorm about some ideas, we are there to help you!"
      ],
      "metadata": {
        "id": "psAUyRUkpT2n"
      }
    }
  ]
}